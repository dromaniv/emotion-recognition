{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c23057",
   "metadata": {},
   "source": [
    "# Emotion Recognition from EEG Signals – GAMEEMO Dataset\n",
    "\n",
    "This notebook demonstrates a **complete baseline pipeline** to train a discrete‐emotion classifier on the [GAMEEMO](https://www.kaggle.com/datasets/sigfest/database-for-emotion-recognition-system-gameemo) EEG dataset. The goal is to predict the **game‐elicited emotion** category:\n",
    "\n",
    "* **Boring** (G1)\n",
    "* **Calm** (G2)\n",
    "* **Horror** (G3)\n",
    "* **Funny** (G4)\n",
    "\n",
    "The dataset is expected to be located in a local `data/` directory adjacent to this notebook (e.g. cloned inside your repository). No internet access or Kaggle API is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q kaggle torch torchvision torchaudio scikit-learn seaborn joblib tqdm\n",
    "\n",
    "import os, re, sys, subprocess, warnings\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = (\n",
    "    torch.device('mps') if torch.backends.mps.is_available() else\n",
    "    torch.device('cuda') if torch.cuda.is_available() else\n",
    "    torch.device('cpu')\n",
    ")\n",
    "print('Running on', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b5e0a",
   "metadata": {},
   "source": [
    "## 1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a206cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT = Path('../data/GAMEEMO')\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(DATA_ROOT.rglob('*.csv')):\n",
    "    print('Downloading GAMEEMO')\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            'kaggle','datasets','download',\n",
    "            '-d','sigfest/database-for-emotion-recognition-system-gameemo',\n",
    "            '-p', str(DATA_ROOT.parent),\n",
    "            '--unzip'\n",
    "        ], check=True)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f'⚠️ Kaggle download failed: {e}\\n')\n",
    "else:\n",
    "    print('Dataset already present – skipping download.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d0147",
   "metadata": {},
   "source": [
    "## 2 File / channel sanity‑check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Only pre‑processed EEG CSVs (each file = one emotion run)\n",
    "csv_files = sorted([p for p in DATA_ROOT.rglob('*.csv')\n",
    "                    if 'Preprocessed' in p.as_posix() and 'Raw' not in p.as_posix()])\n",
    "print('Files found:', len(csv_files))\n",
    "\n",
    "GAME_ID_TO_LABEL = {'G1':'Boring', 'G2':'Calm', 'G3':'Horror', 'G4':'Funny'}\n",
    "label2idx = {v:i for i,v in enumerate(GAME_ID_TO_LABEL.values())}\n",
    "idx2label = {i:l for l,i in label2idx.items()}\n",
    "\n",
    "def label_from_path(p:Path):\n",
    "    m = re.search(r'G[1-4]', p.stem, re.I)\n",
    "    if m: return GAME_ID_TO_LABEL[m.group(0).upper()]\n",
    "    for l in GAME_ID_TO_LABEL.values():\n",
    "        if l.lower() in p.stem.lower(): return l\n",
    "    raise ValueError(f'No label for {p}')\n",
    "\n",
    "# Determine intersection of numeric EEG channels across every CSV\n",
    "common_cols = None\n",
    "for fp in csv_files:\n",
    "    cols = set(pd.read_csv(fp, nrows=1).select_dtypes('number').columns)\n",
    "    common_cols = cols if common_cols is None else (common_cols & cols)\n",
    "common_cols = sorted(common_cols)\n",
    "N_CH = len(common_cols)\n",
    "print('Shared channels:', N_CH, common_cols)\n",
    "\n",
    "FS, WIN_SEC = 128, 3                           # GAMEEMO constants\n",
    "WIN_SAMP = FS * WIN_SEC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842440d",
   "metadata": {},
   "source": [
    "## 3 Feature helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Helper functions ----------------------------------------\n",
    "def iter_windows(arr, win_len):\n",
    "    \"\"\"Yield consecutive, non‑overlapping windows of fixed length.\"\"\"\n",
    "    n_win = len(arr)//win_len\n",
    "    for i in range(n_win):\n",
    "        yield arr[i*win_len:(i+1)*win_len]\n",
    "\n",
    "BANDS = {'delta':(1,4),'theta':(4,8),'alpha':(8,13),'beta':(13,30),'gamma':(30,45)}\n",
    "N_B   = len(BANDS)\n",
    "\n",
    "def stat_features(windows):\n",
    "    \"\"\"Per‑channel mean/std/var/skew/kurt – returned shape (n_win, ch*5).\"\"\"\n",
    "    feats=[]\n",
    "    for w in windows:\n",
    "        f=[]\n",
    "        for ch in range(N_CH):\n",
    "            x = w[ch]\n",
    "            f.extend([x.mean(), x.std(), x.var(), skew(x), kurtosis(x)])\n",
    "        feats.append(f)\n",
    "    return np.asarray(feats, np.float32)\n",
    "\n",
    "def band_features(windows):\n",
    "    \"\"\"Sum of PSD inside canonical EEG sub‑bands for each channel.\"\"\"\n",
    "    feats=[]\n",
    "    for w in windows:\n",
    "        row=[]\n",
    "        for ch in range(N_CH):\n",
    "            f, p = welch(w[ch], FS, nperseg=WIN_SAMP)\n",
    "            for lo,hi in BANDS.values():\n",
    "                row.append(p[(f>=lo)&(f<=hi)].sum())\n",
    "        feats.append(row)\n",
    "    return np.asarray(feats, np.float32)\n",
    "\n",
    "def clean(arr):\n",
    "    \"\"\"Replace NaN/Inf with 0, operate in‑place.\"\"\"\n",
    "    np.nan_to_num(arr, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5ff21",
   "metadata": {},
   "source": [
    "### 3.1 Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79875d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stat_all, band_all, raw_all, y_all, groups = [], [], [], [], []\n",
    "\n",
    "for file_idx, fp in enumerate(tqdm(csv_files, desc='building')):\n",
    "    label = label_from_path(fp)\n",
    "    df = pd.read_csv(fp, usecols=common_cols)\n",
    "    sig = df.to_numpy(np.float32)\n",
    "\n",
    "    # Channel‑wise z‑score (helps CNN converge)\n",
    "    sig = (sig - sig.mean(0)) / (sig.std(0)+1e-6)\n",
    "\n",
    "    # Generate windows\n",
    "    windows = list(iter_windows(sig, WIN_SAMP))\n",
    "    if not windows:\n",
    "        continue\n",
    "    windows = np.stack(windows)              # (n_win, time, ch)\n",
    "    windows = windows.transpose(0,2,1)       # (n_win, ch, time) – CNN expects (B,C,T)\n",
    "\n",
    "    # Hand‑crafted features\n",
    "    stats = clean(stat_features(windows))\n",
    "    bands = clean(band_features(windows))\n",
    "\n",
    "    n_win = len(windows)\n",
    "    stat_all.append(stats)\n",
    "    band_all.append(bands)\n",
    "    raw_all.append(windows)\n",
    "    y_all.append(np.full(n_win, label2idx[label]))\n",
    "    groups.extend([file_idx]*n_win)          # file index acts as \"group\"\n",
    "\n",
    "X_stat = np.concatenate(stat_all)\n",
    "X_band = np.concatenate(band_all)\n",
    "X_raw  = np.concatenate(raw_all)\n",
    "y      = np.concatenate(y_all)\n",
    "groups = np.asarray(groups)\n",
    "\n",
    "X_comb = clean(np.concatenate([X_stat, X_band], 1))\n",
    "\n",
    "print('Windows total:', len(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edf0d1",
   "metadata": {},
   "source": [
    "## 4 Group‑aware train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One full CSV per split (no leakage)\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=RANDOM_SEED)\n",
    "train_idx, test_idx = next(gss.split(X_stat, y, groups=groups))\n",
    "\n",
    "idx_train, idx_test = train_idx, test_idx\n",
    "y_train, y_test = y[idx_train], y[idx_test]\n",
    "\n",
    "splits = {\n",
    "    'stat': (X_stat[idx_train], X_stat[idx_test]),\n",
    "    'comb': (X_comb[idx_train], X_comb[idx_test]),\n",
    "    'raw' : (X_raw[idx_train],  X_raw[idx_test])\n",
    "}\n",
    "print('Train windows:', len(idx_train), '| Test windows:', len(idx_test))\n",
    "\n",
    "# Helper for confusion matrices\n",
    "def plot_cm(y_true, y_pred, title):\n",
    "    labels = [idx2label[i] for i in range(len(idx2label))]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    cmn = cm / cm.sum(1, keepdims=True)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "    plt.title(title); plt.xlabel('Pred'); plt.ylabel('True')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5485efc",
   "metadata": {},
   "source": [
    "## 5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tr, X_te = splits['stat']\n",
    "rf = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='median')),\n",
    "    ('sc',  StandardScaler()),\n",
    "    ('rf',  RandomForestClassifier(\n",
    "                n_estimators=400,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1,\n",
    "                random_state=RANDOM_SEED))\n",
    "])\n",
    "rf.fit(X_tr, y_train)\n",
    "rf_pred = rf.predict(X_te)\n",
    "print('RF accuracy:', accuracy_score(y_test, rf_pred)*100)\n",
    "plot_cm(y_test, rf_pred, 'Random Forest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09a63f",
   "metadata": {},
   "source": [
    "## 6 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ce245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODELS_DIR = Path('../models'); MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(rf, MODELS_DIR/'rf_stat.joblib')\n",
    "print('Models saved →', MODELS_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
