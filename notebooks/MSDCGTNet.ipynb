{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a60650",
   "metadata": {},
   "source": [
    "# EEG Emotion Recognition on GAMEEMO\n",
    "\n",
    "This notebook trains a lightweight **MSDCGTNet** model on the GAMEEMO EEG dataset to classify four game‑evoked emotions:\n",
    "\n",
    "| Label | ID | Description |\n",
    "|-------|----|-------------|\n",
    "| 0 | G1 | Boring |\n",
    "| 1 | G2 | Calm |\n",
    "| 2 | G3 | Horror |\n",
    "| 3 | G4 | Funny |\n",
    "\n",
    "Run the notebook top‑to‑bottom to:\n",
    "\n",
    "1. Download and organise the data  \n",
    "2. Build subject‑wise train / validation splits  \n",
    "3. Train MSDCGTNet with early stopping & mixed precision  \n",
    "4. Inspect metrics and a confusion matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82de814",
   "metadata": {},
   "source": [
    "## About the GAMEEMO dataset\n",
    "\n",
    "* **28 subjects** recorded with a 14‑channel Emotiv Epoc + headset  \n",
    "* **4 five‑minute sessions** per subject – each labelled *Boring*, *Calm*, *Horror* or *Funny*  \n",
    "* Data provided as **pre‑processed CSV** (clean, notch‑filtered, 256 Hz)\n",
    "\n",
    "The goal is to recognise the game‑elicited emotion from raw EEG.  \n",
    "We evaluate with a **subject‑wise split** to report true generalisation to unseen people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b129672",
   "metadata": {},
   "source": [
    "## 0 Setup & data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a06a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already present - skipping download.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(DATA_ROOT.rglob(\"*.csv\")):\n",
    "    print(\"Downloading GAMEEMO\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"datasets\", \"download\",\n",
    "            \"-d\", \"sigfest/database-for-emotion-recognition-system-gameemo\",\n",
    "            \"-p\", str(DATA_ROOT.parent), \"--unzip\",\n",
    "        ], check=True)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f\"⚠️ Kaggle download failed: {e}\\n\")\n",
    "else:\n",
    "    print(\"Dataset already present - skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b9b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 recordings\n",
      "Class counts: [28.0, 28.0, 28.0, 28.0] → weights: [1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path, re\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\")\n",
    "\n",
    "def g_label(fn): return int(re.search(r\"G([1-4])\", fn).group(1)) - 1\n",
    "eeg_paths, labels = [], []\n",
    "for subj in DATA_ROOT.iterdir():\n",
    "    if not subj.is_dir() or not re.fullmatch(r\"\\(S\\d{2}\\)\", subj.name): continue\n",
    "    csv_dir = subj / \"Preprocessed EEG Data\" / \".csv format\"\n",
    "    for p in csv_dir.glob(\"*.csv\"):\n",
    "        eeg_paths.append(p); labels.append(g_label(p.name))\n",
    "print(f\"Found {len(eeg_paths)} recordings\")\n",
    "\n",
    "from collections import Counter\n",
    "import torch\n",
    "cnt = Counter(labels)\n",
    "counts = torch.tensor([cnt.get(i,0) for i in range(4)], dtype=torch.float32)\n",
    "class_weights = 1.0 / counts\n",
    "class_weights = class_weights / class_weights.sum() * 4\n",
    "print(\"Class counts:\", counts.tolist(), \"→ weights:\", class_weights.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9628f",
   "metadata": {},
   "source": [
    "## 1 Dataset & DataLoader construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ac68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: torch.Size([8, 15, 9564])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "class GameEmoEEG(Dataset):\n",
    "    \"\"\"CSV → tensor [n_channels, time]  @64 Hz (down‑sampled).\"\"\"\n",
    "    def __init__(self, paths, labels, ds=4):\n",
    "        self.p, self.y, self.ds = paths, labels, ds\n",
    "    def __len__(self):\n",
    "        return len(self.p)\n",
    "    def __getitem__(self, idx):\n",
    "        df = (\n",
    "            pd.read_csv(self.p[idx], header=None)\n",
    "              .apply(pd.to_numeric, errors='coerce')\n",
    "              .fillna(0.0)\n",
    "        )\n",
    "        x = torch.tensor(df.values.T, dtype=torch.float32)[:, :: self.ds]\n",
    "        # per‑sample z‑score normalization (channel‑wise)\n",
    "        x = (x - x.mean(dim=1, keepdim=True)) / (x.std(dim=1, keepdim=True) + 1e-6)\n",
    "        return x, torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "def _subject_from_path(p):\n",
    "    # (S01) is 4th ancestor of CSV file: .../GAMEEMO/(S01)/Preprocessed EEG Data/.csv format/file.csv\n",
    "    for part in p.parts[::-1]:\n",
    "        if part.startswith(\"(S\") and part.endswith(\")\"):\n",
    "            return part\n",
    "    raise ValueError(f\"Cannot parse subject from path: {p}\")\n",
    "\n",
    "subjects = [_subject_from_path(p) for p in eeg_paths]\n",
    "unique_subj = sorted(set(subjects))\n",
    "rng = np.random.default_rng(42)\n",
    "rng.shuffle(unique_subj)\n",
    "val_ratio = 0.20\n",
    "n_val = max(1, int(len(unique_subj) * val_ratio))\n",
    "val_subj = set(unique_subj[:n_val])\n",
    "\n",
    "train_idx = [i for i, s in enumerate(subjects) if s not in val_subj]\n",
    "test_idx  = [i for i, s in enumerate(subjects) if s in val_subj]\n",
    "\n",
    "BATCH = 8\n",
    "train_loader = DataLoader(\n",
    "    GameEmoEEG([eeg_paths[i] for i in train_idx], [labels[i] for i in train_idx]),\n",
    "    batch_size=BATCH, shuffle=True, drop_last=True, num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    GameEmoEEG([eeg_paths[i] for i in test_idx], [labels[i] for i in test_idx]),\n",
    "    batch_size=BATCH, num_workers=0,\n",
    ")\n",
    "\n",
    "sample, _ = next(iter(train_loader))\n",
    "N_CHANNELS, N_CLASSES = sample.shape[1], 4  # channels count is dim 1\n",
    "print('Sample shape:', sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd889ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 92 samples (11 batches)\n",
      "Val set size:   20 samples (3 batches)\n"
     ]
    }
   ],
   "source": [
    "## Dataset sizes\n",
    "print(f\"Train set size: {len(train_loader.dataset):,} samples ({len(train_loader):,} batches)\")\n",
    "print(f\"Val set size:   {len(test_loader.dataset):,} samples ({len(test_loader):,} batches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ed5d8",
   "metadata": {},
   "source": [
    "## 2 Model definition – MSDCGTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2aea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn, torch\n",
    "class MSDCGTNet(nn.Module):\n",
    "    def __init__(self, c_in, n_cls, d=64, heads=4, layers=2):\n",
    "        super().__init__()\n",
    "        self.c3 = nn.Conv1d(c_in, d, 3, 1, 1)\n",
    "        self.c5 = nn.Conv1d(c_in, d, 5, 1, 2)\n",
    "        self.c7 = nn.Conv1d(c_in, d, 7, 1, 3)\n",
    "        self.bn = nn.BatchNorm1d(3 * d)\n",
    "        self.act = nn.ReLU()\n",
    "        self.reduce = nn.AvgPool1d(4, 4)        \n",
    "        enc = nn.TransformerEncoderLayer(3 * d, heads, 4 * d, batch_first=True)\n",
    "        self.tr = nn.TransformerEncoder(enc, layers)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(3 * d, n_cls)\n",
    "\n",
    "    def forward(self, x):                       # x [B, C, T]\n",
    "        x = torch.cat([self.c3(x), self.c5(x), self.c7(x)], 1)\n",
    "        x = self.act(self.bn(x))\n",
    "        x = self.reduce(x)                      #  <-- sequence length ÷ 4\n",
    "        x = self.tr(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = MSDCGTNet(N_CHANNELS, N_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aaee76",
   "metadata": {},
   "source": [
    "## 3 Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4 Training — tuned hyper‑params + EarlyStopping + F1\n",
    "import torch.nn.functional as F, torch.optim as optim, time\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import deque\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-3\n",
    "EPOCHS = 30\n",
    "PATIENCE = 5\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience):\n",
    "        self.best = float('inf')\n",
    "        self.patience = patience\n",
    "        self.num_bad = 0\n",
    "    def step(self, metric):\n",
    "        if metric < self.best:\n",
    "            self.best = metric\n",
    "            self.num_bad = 0\n",
    "            return False  # keep going\n",
    "        else:\n",
    "            self.num_bad += 1\n",
    "            return self.num_bad > self.patience\n",
    "\n",
    "stopper = EarlyStopper(PATIENCE)\n",
    "scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())  # mixed precision\n",
    "\n",
    "def run(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    tot = correct = loss_sum = 0.0\n",
    "    all_pred, all_true = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with torch.amp.autocast(enabled=torch.cuda.is_available(), device_type=device.type):\n",
    "                out = model(x)\n",
    "                loss = F.cross_entropy(out, y, weight=class_weights.to(device))\n",
    "            if train:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "        pred = out.argmax(1)\n",
    "        all_pred.extend(pred.cpu().numpy())\n",
    "        all_true.extend(y.cpu().numpy())\n",
    "        correct += (pred == y).sum().item()\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "        tot += y.size(0)\n",
    "    acc = correct / tot\n",
    "    f1 = f1_score(all_true, all_pred, average='macro')\n",
    "    return acc, loss_sum / tot, f1\n",
    "\n",
    "start = time.time()\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    tr_a, tr_l, tr_f1 = run(train_loader, True)\n",
    "    v_a, v_l, v_f1 = run(test_loader, False)\n",
    "    scheduler.step(v_l)\n",
    "    lr_now = opt.param_groups[0]['lr']\n",
    "    print(f\"Ep{ep:02d}: train {tr_a:.3f}, {tr_l:.3f} | val {v_a:.3f}, {v_l:.3f} | f1 {v_f1:.3f} | lr {lr_now:.1e}\")\n",
    "    if stopper.step(v_l):\n",
    "        print(\"Early stopping❗\")\n",
    "        break\n",
    "print(\"Total:\", round(time.time() - start, 1), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f7232",
   "metadata": {},
   "source": [
    "## 4 Evaluation & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ccf141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Boring       0.71      0.71      0.71         7\n",
      "        Calm       0.83      0.71      0.77         7\n",
      "      Horror       0.75      0.86      0.80         7\n",
      "       Funny       0.71      0.71      0.71         7\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.75      0.75        28\n",
      "weighted avg       0.75      0.75      0.75        28\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "model.eval(); y_t,y_p=[],[]\n",
    "with torch.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        y_p.extend(model(x.to(device)).argmax(1).cpu().numpy())\n",
    "        y_t.extend(y.numpy())\n",
    "classes=['Boring','Calm','Horror','Funny']\n",
    "print(classification_report(y_t,y_p,target_names=classes))\n",
    "cm=confusion_matrix(y_t,y_p)\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.imshow(cm,cmap='Blues')\n",
    "ax.set_xticks(range(4)); ax.set_yticks(range(4))\n",
    "ax.set_xticklabels(classes); ax.set_yticklabels(classes)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax.text(j,i,cm[i,j],ha='center',va='center',\n",
    "                color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc46ea",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- **MSDCGTNet**: Multi-Scale Dynamic 1D CNN + Gated Transformer network for EEG emotion recognition, combining spatial-spectral feature extraction with long-range dependency modeling.  \n",
    "- **Vaswani et al., 2017**: “Attention Is All You Need,” in *Advances in Neural Information Processing Systems*.  \n",
    "- **Türkan et al., 2020**: “EEG Signals and Various Computer Games (GAMEEMO),” *Biomedical Signal Processing and Control*, DOI:10.1016/j.bspc.2020.101951.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
