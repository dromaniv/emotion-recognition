{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a60650",
   "metadata": {},
   "source": [
    "# EEG Emotion Recognition on GAMEEMO\n",
    "\n",
    "This notebook trains a lightweight **MSDCGTNet** model on the GAMEEMO EEG dataset to classify four game‑evoked emotions:\n",
    "\n",
    "| Label | ID | Description |\n",
    "|-------|----|-------------|\n",
    "| 0 | G1 | Boring |\n",
    "| 1 | G2 | Calm |\n",
    "| 2 | G3 | Horror |\n",
    "| 3 | G4 | Funny |\n",
    "\n",
    "Run the notebook top‑to‑bottom to:\n",
    "\n",
    "1. Download and organise the data  \n",
    "2. Build subject‑wise train / validation splits  \n",
    "3. Train MSDCGTNet with early stopping & mixed precision  \n",
    "4. Inspect metrics and a confusion matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82de814",
   "metadata": {},
   "source": [
    "## About the GAMEEMO dataset\n",
    "\n",
    "* **28 subjects** recorded with a 14‑channel Emotiv Epoc + headset  \n",
    "* **4 five‑minute sessions** per subject – each labelled *Boring*, *Calm*, *Horror* or *Funny*  \n",
    "* Data provided as **pre‑processed CSV** (clean, notch‑filtered, 256 Hz)\n",
    "\n",
    "The goal is to recognise the game‑elicited emotion from raw EEG.  \n",
    "We evaluate with a **subject‑wise split** to report true generalisation to unseen people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b129672",
   "metadata": {},
   "source": [
    "## 0 Setup & data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a06a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already present - skipping download.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(DATA_ROOT.rglob(\"*.csv\")):\n",
    "    print(\"Downloading GAMEEMO\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"datasets\", \"download\",\n",
    "            \"-d\", \"sigfest/database-for-emotion-recognition-system-gameemo\",\n",
    "            \"-p\", str(DATA_ROOT.parent), \"--unzip\",\n",
    "        ], check=True)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f\"⚠️ Kaggle download failed: {e}\\n\")\n",
    "else:\n",
    "    print(\"Dataset already present - skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b9b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 recordings\n",
      "Class counts: [28.0, 28.0, 28.0, 28.0] → weights: [1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path, re\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\")\n",
    "\n",
    "def g_label(fn): return int(re.search(r\"G([1-4])\", fn).group(1)) - 1\n",
    "eeg_paths, labels = [], []\n",
    "for subj in DATA_ROOT.iterdir():\n",
    "    if not subj.is_dir() or not re.fullmatch(r\"\\(S\\d{2}\\)\", subj.name): continue\n",
    "    csv_dir = subj / \"Preprocessed EEG Data\" / \".csv format\"\n",
    "    for p in csv_dir.glob(\"*.csv\"):\n",
    "        eeg_paths.append(p); labels.append(g_label(p.name))\n",
    "print(f\"Found {len(eeg_paths)} recordings\")\n",
    "\n",
    "from collections import Counter\n",
    "import torch\n",
    "cnt = Counter(labels)\n",
    "counts = torch.tensor([cnt.get(i,0) for i in range(4)], dtype=torch.float32)\n",
    "class_weights = 1.0 / counts\n",
    "class_weights = class_weights / class_weights.sum() * 4\n",
    "print(\"Class counts:\", counts.tolist(), \"→ weights:\", class_weights.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9628f",
   "metadata": {},
   "source": [
    "## 1 Dataset & DataLoader construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ac68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: torch.Size([8, 15, 9564])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "class GameEmoEEG(Dataset):\n",
    "    \"\"\"CSV → tensor [n_channels, time]  @64 Hz (down‑sampled).\"\"\"\n",
    "    def __init__(self, paths, labels, ds=4):\n",
    "        self.p, self.y, self.ds = paths, labels, ds\n",
    "    def __len__(self):\n",
    "        return len(self.p)\n",
    "    def __getitem__(self, idx):\n",
    "        df = (\n",
    "            pd.read_csv(self.p[idx], header=None)\n",
    "              .apply(pd.to_numeric, errors='coerce')\n",
    "              .fillna(0.0)\n",
    "        )\n",
    "        x = torch.tensor(df.values.T, dtype=torch.float32)[:, :: self.ds]\n",
    "        # per‑sample z‑score normalization (channel‑wise)\n",
    "        x = (x - x.mean(dim=1, keepdim=True)) / (x.std(dim=1, keepdim=True) + 1e-6)\n",
    "        return x, torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "def _subject_from_path(p):\n",
    "    # (S01) is 4th ancestor of CSV file: .../GAMEEMO/(S01)/Preprocessed EEG Data/.csv format/file.csv\n",
    "    for part in p.parts[::-1]:\n",
    "        if part.startswith(\"(S\") and part.endswith(\")\"):\n",
    "            return part\n",
    "    raise ValueError(f\"Cannot parse subject from path: {p}\")\n",
    "\n",
    "subjects = [_subject_from_path(p) for p in eeg_paths]\n",
    "unique_subj = sorted(set(subjects))\n",
    "rng = np.random.default_rng(42)\n",
    "rng.shuffle(unique_subj)\n",
    "val_ratio = 0.25\n",
    "n_val = max(1, int(len(unique_subj) * val_ratio))\n",
    "val_subj = set(unique_subj[:n_val])\n",
    "\n",
    "train_idx = [i for i, s in enumerate(subjects) if s not in val_subj]\n",
    "test_idx  = [i for i, s in enumerate(subjects) if s in val_subj]\n",
    "\n",
    "BATCH = 8\n",
    "train_loader = DataLoader(\n",
    "    GameEmoEEG([eeg_paths[i] for i in train_idx], [labels[i] for i in train_idx]),\n",
    "    batch_size=BATCH, shuffle=True, drop_last=True, num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    GameEmoEEG([eeg_paths[i] for i in test_idx], [labels[i] for i in test_idx]),\n",
    "    batch_size=BATCH, num_workers=0,\n",
    ")\n",
    "\n",
    "sample, _ = next(iter(train_loader))\n",
    "N_CHANNELS, N_CLASSES = sample.shape[1], 4  # channels count is dim 1\n",
    "print('Sample shape:', sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd889ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 84 samples (10 batches)\n",
      "Val set size:   28 samples (4 batches)\n"
     ]
    }
   ],
   "source": [
    "## Dataset sizes\n",
    "print(f\"Train set size: {len(train_loader.dataset):,} samples ({len(train_loader):,} batches)\")\n",
    "print(f\"Val set size:   {len(test_loader.dataset):,} samples ({len(test_loader):,} batches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ed5d8",
   "metadata": {},
   "source": [
    "## 2 Model definition – MSDCGTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2aea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn, torch\n",
    "class MSDCGTNet(nn.Module):\n",
    "    def __init__(self, c_in, n_cls, d=64, heads=4, layers=2):\n",
    "        super().__init__()\n",
    "        self.c3 = nn.Conv1d(c_in, d, 3, 1, 1)\n",
    "        self.c5 = nn.Conv1d(c_in, d, 5, 1, 2)\n",
    "        self.c7 = nn.Conv1d(c_in, d, 7, 1, 3)\n",
    "        self.bn = nn.BatchNorm1d(3 * d)\n",
    "        self.act = nn.ReLU()\n",
    "        self.reduce = nn.AvgPool1d(4, 4)        \n",
    "        enc = nn.TransformerEncoderLayer(3 * d, heads, 4 * d, batch_first=True)\n",
    "        self.tr = nn.TransformerEncoder(enc, layers)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(3 * d, n_cls)\n",
    "\n",
    "    def forward(self, x):                       # x [B, C, T]\n",
    "        x = torch.cat([self.c3(x), self.c5(x), self.c7(x)], 1)\n",
    "        x = self.act(self.bn(x))\n",
    "        x = self.reduce(x)                      #  <-- sequence length ÷ 4\n",
    "        x = self.tr(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = MSDCGTNet(N_CHANNELS, N_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aaee76",
   "metadata": {},
   "source": [
    "## 3 Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eed6c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep01: train 0.237, 1.480 | val 0.250, 1.442 | f1 0.100 | lr 3.0e-04\n",
      "Ep02: train 0.237, 1.425 | val 0.250, 1.398 | f1 0.100 | lr 3.0e-04\n",
      "Ep03: train 0.338, 1.362 | val 0.286, 1.396 | f1 0.183 | lr 3.0e-04\n",
      "Ep04: train 0.412, 1.382 | val 0.429, 1.326 | f1 0.375 | lr 3.0e-04\n",
      "Ep05: train 0.412, 1.292 | val 0.357, 1.280 | f1 0.293 | lr 3.0e-04\n",
      "Ep06: train 0.400, 1.241 | val 0.464, 1.162 | f1 0.412 | lr 3.0e-04\n",
      "Ep07: train 0.438, 1.128 | val 0.536, 1.084 | f1 0.511 | lr 3.0e-04\n",
      "Ep08: train 0.575, 0.971 | val 0.500, 1.113 | f1 0.419 | lr 3.0e-04\n",
      "Ep09: train 0.600, 0.826 | val 0.607, 0.957 | f1 0.582 | lr 3.0e-04\n",
      "Ep10: train 0.675, 0.688 | val 0.679, 0.833 | f1 0.664 | lr 3.0e-04\n",
      "Ep11: train 0.812, 0.552 | val 0.679, 0.807 | f1 0.670 | lr 3.0e-04\n",
      "Ep12: train 0.900, 0.366 | val 0.750, 0.600 | f1 0.749 | lr 3.0e-04\n",
      "Ep13: train 0.925, 0.265 | val 0.821, 0.428 | f1 0.818 | lr 3.0e-04\n",
      "Ep14: train 0.950, 0.165 | val 0.786, 0.452 | f1 0.787 | lr 3.0e-04\n",
      "Ep15: train 0.963, 0.143 | val 0.857, 0.556 | f1 0.859 | lr 3.0e-04\n",
      "Ep16: train 0.988, 0.085 | val 0.750, 0.657 | f1 0.744 | lr 3.0e-04\n",
      "Ep17: train 1.000, 0.037 | val 0.893, 0.561 | f1 0.891 | lr 1.5e-04\n",
      "Ep18: train 1.000, 0.017 | val 0.893, 0.449 | f1 0.891 | lr 1.5e-04\n",
      "Ep19: train 1.000, 0.009 | val 0.857, 0.575 | f1 0.854 | lr 1.5e-04\n",
      "Early stopping❗\n",
      "Total: 1148.2 s\n"
     ]
    }
   ],
   "source": [
    "## 4 Training — tuned hyper‑params + EarlyStopping + F1\n",
    "import torch.nn.functional as F, torch.optim as optim, time\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import deque\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-3\n",
    "EPOCHS = 30\n",
    "PATIENCE = 5\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience):\n",
    "        self.best = float('inf')\n",
    "        self.patience = patience\n",
    "        self.num_bad = 0\n",
    "    def step(self, metric):\n",
    "        if metric < self.best:\n",
    "            self.best = metric\n",
    "            self.num_bad = 0\n",
    "            return False  # keep going\n",
    "        else:\n",
    "            self.num_bad += 1\n",
    "            return self.num_bad > self.patience\n",
    "\n",
    "stopper = EarlyStopper(PATIENCE)\n",
    "scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())  # mixed precision\n",
    "\n",
    "def run(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    tot = correct = loss_sum = 0.0\n",
    "    all_pred, all_true = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with torch.amp.autocast(enabled=torch.cuda.is_available(), device_type=device.type):\n",
    "                out = model(x)\n",
    "                loss = F.cross_entropy(out, y, weight=class_weights.to(device))\n",
    "            if train:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "        pred = out.argmax(1)\n",
    "        all_pred.extend(pred.cpu().numpy())\n",
    "        all_true.extend(y.cpu().numpy())\n",
    "        correct += (pred == y).sum().item()\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "        tot += y.size(0)\n",
    "    acc = correct / tot\n",
    "    f1 = f1_score(all_true, all_pred, average='macro')\n",
    "    return acc, loss_sum / tot, f1\n",
    "\n",
    "start = time.time()\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    tr_a, tr_l, tr_f1 = run(train_loader, True)\n",
    "    v_a, v_l, v_f1 = run(test_loader, False)\n",
    "    scheduler.step(v_l)\n",
    "    lr_now = opt.param_groups[0]['lr']\n",
    "    print(f\"Ep{ep:02d}: train {tr_a:.3f}, {tr_l:.3f} | val {v_a:.3f}, {v_l:.3f} | f1 {v_f1:.3f} | lr {lr_now:.1e}\")\n",
    "    if stopper.step(v_l):\n",
    "        print(\"Early stopping❗\")\n",
    "        break\n",
    "print(\"Total:\", round(time.time() - start, 1), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f7232",
   "metadata": {},
   "source": [
    "## 4 Evaluation & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ccf141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Boring       0.78      1.00      0.88         7\n",
      "        Calm       1.00      0.71      0.83         7\n",
      "      Horror       0.78      1.00      0.88         7\n",
      "       Funny       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.86        28\n",
      "   macro avg       0.89      0.86      0.85        28\n",
      "weighted avg       0.89      0.86      0.85        28\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "model.eval(); y_t,y_p=[],[]\n",
    "with torch.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        y_p.extend(model(x.to(device)).argmax(1).cpu().numpy())\n",
    "        y_t.extend(y.numpy())\n",
    "classes=['Boring','Calm','Horror','Funny']\n",
    "print(classification_report(y_t,y_p,target_names=classes))\n",
    "cm=confusion_matrix(y_t,y_p)\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.imshow(cm,cmap='Blues')\n",
    "ax.set_xticks(range(4)); ax.set_yticks(range(4))\n",
    "ax.set_xticklabels(classes); ax.set_yticklabels(classes)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax.text(j,i,cm[i,j],ha='center',va='center',\n",
    "                color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc46ea",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- **MSDCGTNet**: Multi-Scale Dynamic 1D CNN + Gated Transformer network for EEG emotion recognition, combining spatial-spectral feature extraction with long-range dependency modeling.  \n",
    "- **Vaswani et al., 2017**: “Attention Is All You Need,” in *Advances in Neural Information Processing Systems*.  \n",
    "- **Türkan et al., 2020**: “EEG Signals and Various Computer Games (GAMEEMO),” *Biomedical Signal Processing and Control*, DOI:10.1016/j.bspc.2020.101951.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
