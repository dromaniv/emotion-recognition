{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a60650",
   "metadata": {},
   "source": [
    "# EEG Emotion Recognition on GAMEEMO\n",
    "\n",
    "This notebook trains a lightweight **MSDCGTNet** model on the GAMEEMO EEG dataset to classify four game‑evoked emotions:\n",
    "\n",
    "| Label | ID | Description |\n",
    "|-------|----|-------------|\n",
    "| 0 | G1 | Boring |\n",
    "| 1 | G2 | Calm |\n",
    "| 2 | G3 | Horror |\n",
    "| 3 | G4 | Funny |\n",
    "\n",
    "Run the notebook top‑to‑bottom to:\n",
    "\n",
    "1. Download and organise the data  \n",
    "2. Build subject‑wise train / validation splits  \n",
    "3. Train MSDCGTNet with early stopping & mixed precision  \n",
    "4. Inspect metrics and a confusion matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82de814",
   "metadata": {},
   "source": [
    "## About the GAMEEMO dataset\n",
    "\n",
    "* **28 subjects** recorded with a 14‑channel Emotiv Epoc + headset  \n",
    "* **4 five‑minute sessions** per subject – each labelled *Boring*, *Calm*, *Horror* or *Funny*  \n",
    "* Data provided as **pre‑processed CSV** (clean, notch‑filtered, 256 Hz)\n",
    "\n",
    "The goal is to recognise the game‑elicited emotion from raw EEG.  \n",
    "We evaluate with a **subject‑wise split** to report true generalisation to unseen people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b129672",
   "metadata": {},
   "source": [
    "## 0 Setup & data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a06a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already present - skipping download.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(DATA_ROOT.rglob(\"*.csv\")):\n",
    "    print(\"Downloading GAMEEMO\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"datasets\", \"download\",\n",
    "            \"-d\", \"sigfest/database-for-emotion-recognition-system-gameemo\",\n",
    "            \"-p\", str(DATA_ROOT.parent), \"--unzip\",\n",
    "        ], check=True)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f\"⚠️ Kaggle download failed: {e}\\n\")\n",
    "else:\n",
    "    print(\"Dataset already present - skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b9b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 recordings\n",
      "Class counts: [28.0, 28.0, 28.0, 28.0] → weights: [1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path, re\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\")\n",
    "\n",
    "def g_label(fn): return int(re.search(r\"G([1-4])\", fn).group(1)) - 1\n",
    "eeg_paths, labels = [], []\n",
    "for subj in DATA_ROOT.iterdir():\n",
    "    if not subj.is_dir() or not re.fullmatch(r\"\\(S\\d{2}\\)\", subj.name): continue\n",
    "    csv_dir = subj / \"Preprocessed EEG Data\" / \".csv format\"\n",
    "    for p in csv_dir.glob(\"*.csv\"):\n",
    "        eeg_paths.append(p); labels.append(g_label(p.name))\n",
    "print(f\"Found {len(eeg_paths)} recordings\")\n",
    "\n",
    "from collections import Counter\n",
    "import torch\n",
    "cnt = Counter(labels)\n",
    "counts = torch.tensor([cnt.get(i,0) for i in range(4)], dtype=torch.float32)\n",
    "class_weights = 1.0 / counts\n",
    "class_weights = class_weights / class_weights.sum() * 4\n",
    "print(\"Class counts:\", counts.tolist(), \"→ weights:\", class_weights.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9628f",
   "metadata": {},
   "source": [
    "## 1 Dataset & DataLoader construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ac68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: torch.Size([8, 15, 9564])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "class GameEmoEEG(Dataset):\n",
    "    \"\"\"CSV → tensor [n_channels, time]  @64 Hz (down‑sampled).\"\"\"\n",
    "    def __init__(self, paths, labels, ds=4):\n",
    "        self.p, self.y, self.ds = paths, labels, ds\n",
    "    def __len__(self):\n",
    "        return len(self.p)\n",
    "    def __getitem__(self, idx):\n",
    "        df = (\n",
    "            pd.read_csv(self.p[idx], header=None)\n",
    "              .apply(pd.to_numeric, errors='coerce')\n",
    "              .fillna(0.0)\n",
    "        )\n",
    "        x = torch.tensor(df.values.T, dtype=torch.float32)[:, :: self.ds]\n",
    "        # per‑sample z‑score normalization (channel‑wise)\n",
    "        x = (x - x.mean(dim=1, keepdim=True)) / (x.std(dim=1, keepdim=True) + 1e-6)\n",
    "        return x, torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "def _subject_from_path(p):\n",
    "    # (S01) is 4th ancestor of CSV file: .../GAMEEMO/(S01)/Preprocessed EEG Data/.csv format/file.csv\n",
    "    for part in p.parts[::-1]:\n",
    "        if part.startswith(\"(S\") and part.endswith(\")\"):\n",
    "            return part\n",
    "    raise ValueError(f\"Cannot parse subject from path: {p}\")\n",
    "\n",
    "subjects = [_subject_from_path(p) for p in eeg_paths]\n",
    "unique_subj = sorted(set(subjects))\n",
    "rng = np.random.default_rng(42)\n",
    "rng.shuffle(unique_subj)\n",
    "val_ratio = 0.20\n",
    "n_val = max(1, int(len(unique_subj) * val_ratio))\n",
    "val_subj = set(unique_subj[:n_val])\n",
    "\n",
    "train_idx = [i for i, s in enumerate(subjects) if s not in val_subj]\n",
    "test_idx  = [i for i, s in enumerate(subjects) if s in val_subj]\n",
    "\n",
    "BATCH = 8\n",
    "train_loader = DataLoader(\n",
    "    GameEmoEEG([eeg_paths[i] for i in train_idx], [labels[i] for i in train_idx]),\n",
    "    batch_size=BATCH, shuffle=True, drop_last=True, num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    GameEmoEEG([eeg_paths[i] for i in test_idx], [labels[i] for i in test_idx]),\n",
    "    batch_size=BATCH, num_workers=0,\n",
    ")\n",
    "\n",
    "sample, _ = next(iter(train_loader))\n",
    "N_CHANNELS, N_CLASSES = sample.shape[1], 4  # channels count is dim 1\n",
    "print('Sample shape:', sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd889ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 92 samples (11 batches)\n",
      "Val set size:   20 samples (3 batches)\n"
     ]
    }
   ],
   "source": [
    "## Dataset sizes\n",
    "print(f\"Train set size: {len(train_loader.dataset):,} samples ({len(train_loader):,} batches)\")\n",
    "print(f\"Val set size:   {len(test_loader.dataset):,} samples ({len(test_loader):,} batches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ed5d8",
   "metadata": {},
   "source": [
    "## 2 Model definition – MSDCGTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2aea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn, torch\n",
    "class MSDCGTNet(nn.Module):\n",
    "    def __init__(self, c_in, n_cls, d=64, heads=4, layers=2):\n",
    "        super().__init__()\n",
    "        self.c3 = nn.Conv1d(c_in, d, 3, 1, 1)\n",
    "        self.c5 = nn.Conv1d(c_in, d, 5, 1, 2)\n",
    "        self.c7 = nn.Conv1d(c_in, d, 7, 1, 3)\n",
    "        self.bn = nn.BatchNorm1d(3 * d)\n",
    "        self.act = nn.ReLU()\n",
    "        self.reduce = nn.AvgPool1d(4, 4)        \n",
    "        enc = nn.TransformerEncoderLayer(3 * d, heads, 4 * d, batch_first=True)\n",
    "        self.tr = nn.TransformerEncoder(enc, layers)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(3 * d, n_cls)\n",
    "\n",
    "    def forward(self, x):                       # x [B, C, T]\n",
    "        x = torch.cat([self.c3(x), self.c5(x), self.c7(x)], 1)\n",
    "        x = self.act(self.bn(x))\n",
    "        x = self.reduce(x)                      #  <-- sequence length ÷ 4\n",
    "        x = self.tr(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = MSDCGTNet(N_CHANNELS, N_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aaee76",
   "metadata": {},
   "source": [
    "## 3 Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eed6c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep01: train 0.205, 1.481 | val 0.300, 1.419 | f1 0.200 | lr 3.0e-04\n",
      "Ep02: train 0.250, 1.466 | val 0.300, 1.372 | f1 0.200 | lr 3.0e-04\n",
      "Ep03: train 0.295, 1.433 | val 0.250, 1.372 | f1 0.100 | lr 3.0e-04\n",
      "Ep04: train 0.261, 1.402 | val 0.200, 1.362 | f1 0.184 | lr 3.0e-04\n",
      "Ep05: train 0.318, 1.377 | val 0.300, 1.345 | f1 0.188 | lr 3.0e-04\n",
      "Ep06: train 0.398, 1.340 | val 0.500, 1.342 | f1 0.435 | lr 3.0e-04\n",
      "Ep07: train 0.420, 1.321 | val 0.350, 1.363 | f1 0.244 | lr 3.0e-04\n",
      "Ep08: train 0.318, 1.322 | val 0.500, 1.327 | f1 0.507 | lr 3.0e-04\n",
      "Ep09: train 0.477, 1.201 | val 0.400, 1.267 | f1 0.375 | lr 3.0e-04\n",
      "Ep10: train 0.614, 0.994 | val 0.450, 1.182 | f1 0.421 | lr 3.0e-04\n",
      "Ep11: train 0.682, 0.822 | val 0.600, 1.035 | f1 0.571 | lr 3.0e-04\n",
      "Ep12: train 0.739, 0.626 | val 0.600, 0.943 | f1 0.567 | lr 3.0e-04\n",
      "Ep13: train 0.784, 0.583 | val 0.600, 0.896 | f1 0.592 | lr 3.0e-04\n",
      "Ep14: train 0.818, 0.457 | val 0.800, 0.666 | f1 0.806 | lr 3.0e-04\n",
      "Ep15: train 0.898, 0.358 | val 0.850, 0.597 | f1 0.852 | lr 3.0e-04\n",
      "Ep16: train 0.909, 0.290 | val 0.800, 0.457 | f1 0.790 | lr 3.0e-04\n",
      "Ep17: train 0.932, 0.206 | val 0.750, 0.473 | f1 0.754 | lr 3.0e-04\n",
      "Ep18: train 0.898, 0.271 | val 0.800, 0.547 | f1 0.800 | lr 3.0e-04\n",
      "Ep19: train 0.989, 0.104 | val 0.800, 0.355 | f1 0.798 | lr 3.0e-04\n",
      "Ep20: train 0.955, 0.166 | val 0.750, 0.517 | f1 0.742 | lr 3.0e-04\n",
      "Ep21: train 0.955, 0.122 | val 0.850, 0.469 | f1 0.850 | lr 3.0e-04\n",
      "Ep22: train 0.955, 0.108 | val 0.850, 0.480 | f1 0.850 | lr 3.0e-04\n",
      "Ep23: train 0.955, 0.116 | val 0.850, 0.482 | f1 0.850 | lr 1.5e-04\n",
      "Ep24: train 0.966, 0.109 | val 0.850, 0.478 | f1 0.850 | lr 1.5e-04\n",
      "Ep25: train 0.966, 0.098 | val 0.850, 0.479 | f1 0.850 | lr 1.5e-04\n",
      "Early stopping❗\n",
      "Total: 1506.5 s\n"
     ]
    }
   ],
   "source": [
    "## 4 Training — tuned hyper‑params + EarlyStopping + F1\n",
    "import torch.nn.functional as F, torch.optim as optim, time\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import deque\n",
    "\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-3\n",
    "EPOCHS = 30\n",
    "PATIENCE = 5\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience):\n",
    "        self.best = float('inf')\n",
    "        self.patience = patience\n",
    "        self.num_bad = 0\n",
    "    def step(self, metric):\n",
    "        if metric < self.best:\n",
    "            self.best = metric\n",
    "            self.num_bad = 0\n",
    "            return False  # keep going\n",
    "        else:\n",
    "            self.num_bad += 1\n",
    "            return self.num_bad > self.patience\n",
    "\n",
    "stopper = EarlyStopper(PATIENCE)\n",
    "scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())  # mixed precision\n",
    "\n",
    "def run(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    tot = correct = loss_sum = 0.0\n",
    "    all_pred, all_true = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with torch.amp.autocast(enabled=torch.cuda.is_available(), device_type=device.type):\n",
    "                out = model(x)\n",
    "                loss = F.cross_entropy(out, y, weight=class_weights.to(device))\n",
    "            if train:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "        pred = out.argmax(1)\n",
    "        all_pred.extend(pred.cpu().numpy())\n",
    "        all_true.extend(y.cpu().numpy())\n",
    "        correct += (pred == y).sum().item()\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "        tot += y.size(0)\n",
    "    acc = correct / tot\n",
    "    f1 = f1_score(all_true, all_pred, average='macro')\n",
    "    return acc, loss_sum / tot, f1\n",
    "\n",
    "start = time.time()\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    tr_a, tr_l, tr_f1 = run(train_loader, True)\n",
    "    v_a, v_l, v_f1 = run(test_loader, False)\n",
    "    scheduler.step(v_l)\n",
    "    lr_now = opt.param_groups[0]['lr']\n",
    "    print(f\"Ep{ep:02d}: train {tr_a:.3f}, {tr_l:.3f} | val {v_a:.3f}, {v_l:.3f} | f1 {v_f1:.3f} | lr {lr_now:.1e}\")\n",
    "    if stopper.step(v_l):\n",
    "        print(\"Early stopping❗\")\n",
    "        break\n",
    "print(\"Total:\", round(time.time() - start, 1), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f7232",
   "metadata": {},
   "source": [
    "## 4 Evaluation & confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ccf141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Boring       0.80      0.80      0.80         5\n",
      "        Calm       0.80      0.80      0.80         5\n",
      "      Horror       1.00      1.00      1.00         5\n",
      "       Funny       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.85      0.85      0.85        20\n",
      "weighted avg       0.85      0.85      0.85        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "model.eval(); y_t,y_p=[],[]\n",
    "with torch.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        y_p.extend(model(x.to(device)).argmax(1).cpu().numpy())\n",
    "        y_t.extend(y.numpy())\n",
    "classes=['Boring','Calm','Horror','Funny']\n",
    "print(classification_report(y_t,y_p,target_names=classes))\n",
    "cm=confusion_matrix(y_t,y_p)\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.imshow(cm,cmap='Blues')\n",
    "ax.set_xticks(range(4)); ax.set_yticks(range(4))\n",
    "ax.set_xticklabels(classes); ax.set_yticklabels(classes)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax.text(j,i,cm[i,j],ha='center',va='center',\n",
    "                color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc46ea",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- **MSDCGTNet**: Multi-Scale Dynamic 1D CNN + Gated Transformer network for EEG emotion recognition, combining spatial-spectral feature extraction with long-range dependency modeling.  \n",
    "- **Vaswani et al., 2017**: “Attention Is All You Need,” in *Advances in Neural Information Processing Systems*.  \n",
    "- **Türkan et al., 2020**: “EEG Signals and Various Computer Games (GAMEEMO),” *Biomedical Signal Processing and Control*, DOI:10.1016/j.bspc.2020.101951.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
