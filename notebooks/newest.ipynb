{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a60650",
   "metadata": {},
   "source": [
    "# EEG Emotion Recognition on GAMEEMO\n",
    "\n",
    "This notebook trains a lightweight **MSDCGTNet** model on the GAMEEMO EEG dataset to classify four game‑evoked emotions:\n",
    "\n",
    "| Label | ID | Description |\n",
    "|-------|----|-------------|\n",
    "| 0 | G1 | Boring |\n",
    "| 1 | G2 | Calm |\n",
    "| 2 | G3 | Horror |\n",
    "| 3 | G4 | Funny |\n",
    "\n",
    "Run the notebook top‑to‑bottom to:\n",
    "\n",
    "1. Download and organise the data  \n",
    "2. Build subject‑wise train / validation splits  \n",
    "3. Train MSDCGTNet with early stopping & mixed precision  \n",
    "4. Inspect metrics and a confusion matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82de814",
   "metadata": {},
   "source": [
    "## About the GAMEEMO dataset\n",
    "\n",
    "* **28 subjects** recorded with a 14‑channel Emotiv Epoc + headset  \n",
    "* **4 five‑minute sessions** per subject – each labelled *Boring*, *Calm*, *Horror* or *Funny*  \n",
    "* Data provided as **pre‑processed CSV** (clean, notch‑filtered, 256 Hz)\n",
    "\n",
    "The goal is to recognise the game‑elicited emotion from raw EEG.  \n",
    "We evaluate with a **subject‑wise split** to report true generalisation to unseen people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b129672",
   "metadata": {},
   "source": [
    "## 0 Setup & data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a06a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already present - skipping download.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(DATA_ROOT.rglob(\"*.csv\")):\n",
    "    print(\"Downloading GAMEEMO\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"datasets\", \"download\",\n",
    "            \"-d\", \"sigfest/database-for-emotion-recognition-system-gameemo\",\n",
    "            \"-p\", str(DATA_ROOT.parent), \"--unzip\",\n",
    "        ], check=True)\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f\"⚠️ Kaggle download failed: {e}\\n\")\n",
    "else:\n",
    "    print(\"Dataset already present - skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b9b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing dataset...\n",
      "Scanning data root: C:\\Users\\dmrom\\emotion-recognition\\data\\GAMEEMO\n",
      "Found 112 recordings from 28 subjects.\n",
      "Number of training samples: 90\n",
      "Number of testing samples: 22\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   4%|▍         | 1/25 [00:07<02:59,  7.47s/it, TrainAcc=0.2778, TrainLoss=1.3986]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 => Train Loss: 1.3986, Train Acc: 0.2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   8%|▊         | 2/25 [00:14<02:43,  7.10s/it, TrainAcc=0.4444, TrainLoss=1.2223]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 => Train Loss: 1.2223, Train Acc: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  12%|█▏        | 3/25 [00:21<02:32,  6.94s/it, TrainAcc=0.7333, TrainLoss=1.0866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 => Train Loss: 1.0866, Train Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  16%|█▌        | 4/25 [00:27<02:25,  6.93s/it, TrainAcc=0.7778, TrainLoss=0.9614]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 => Train Loss: 0.9614, Train Acc: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  16%|█▌        | 4/25 [00:34<02:25,  6.93s/it, TrainAcc=0.8111, TrainLoss=0.7962]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 => Train Loss: 0.7962, Train Acc: 0.8111"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 5/25 [00:36<02:28,  7.45s/it, TrainAcc=0.8111, TrainLoss=0.7962, ValAcc=0.6818, ValLoss=0.9421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Val Loss: 0.9421, Val Acc: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  24%|██▍       | 6/25 [00:43<02:16,  7.19s/it, TrainAcc=0.8778, TrainLoss=0.6340]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 => Train Loss: 0.6340, Train Acc: 0.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  28%|██▊       | 7/25 [00:49<02:07,  7.09s/it, TrainAcc=0.9111, TrainLoss=0.5011]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 => Train Loss: 0.5011, Train Acc: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  32%|███▏      | 8/25 [00:56<01:59,  7.04s/it, TrainAcc=0.9778, TrainLoss=0.3620]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 => Train Loss: 0.3620, Train Acc: 0.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  36%|███▌      | 9/25 [01:03<01:51,  6.98s/it, TrainAcc=0.9889, TrainLoss=0.2520]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 => Train Loss: 0.2520, Train Acc: 0.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  36%|███▌      | 9/25 [01:10<01:51,  6.98s/it, TrainAcc=0.9889, TrainLoss=0.1902]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 => Train Loss: 0.1902, Train Acc: 0.9889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 10/25 [01:12<01:51,  7.45s/it, TrainAcc=0.9889, TrainLoss=0.1902, ValAcc=0.9091, ValLoss=0.3783]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Val Loss: 0.3783, Val Acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  44%|████▍     | 11/25 [01:19<01:42,  7.31s/it, TrainAcc=1.0000, TrainLoss=0.1134]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 => Train Loss: 0.1134, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  48%|████▊     | 12/25 [01:26<01:34,  7.23s/it, TrainAcc=1.0000, TrainLoss=0.0697]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 => Train Loss: 0.0697, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  52%|█████▏    | 13/25 [01:33<01:25,  7.13s/it, TrainAcc=1.0000, TrainLoss=0.0559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 => Train Loss: 0.0559, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  56%|█████▌    | 14/25 [01:39<01:16,  6.98s/it, TrainAcc=1.0000, TrainLoss=0.0332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 => Train Loss: 0.0332, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  56%|█████▌    | 14/25 [01:46<01:16,  6.98s/it, TrainAcc=1.0000, TrainLoss=0.0258]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 => Train Loss: 0.0258, Train Acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 15/25 [01:48<01:14,  7.47s/it, TrainAcc=1.0000, TrainLoss=0.0258, ValAcc=0.9545, ValLoss=0.2318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Val Loss: 0.2318, Val Acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  64%|██████▍   | 16/25 [01:55<01:05,  7.31s/it, TrainAcc=1.0000, TrainLoss=0.0204]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 => Train Loss: 0.0204, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  68%|██████▊   | 17/25 [02:02<00:57,  7.17s/it, TrainAcc=1.0000, TrainLoss=0.0163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 => Train Loss: 0.0163, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  72%|███████▏  | 18/25 [02:09<00:50,  7.15s/it, TrainAcc=1.0000, TrainLoss=0.0137]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 => Train Loss: 0.0137, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  76%|███████▌  | 19/25 [02:16<00:42,  7.09s/it, TrainAcc=1.0000, TrainLoss=0.0119]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 => Train Loss: 0.0119, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  76%|███████▌  | 19/25 [02:23<00:42,  7.09s/it, TrainAcc=1.0000, TrainLoss=0.0104]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 => Train Loss: 0.0104, Train Acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 20/25 [02:24<00:37,  7.55s/it, TrainAcc=1.0000, TrainLoss=0.0104, ValAcc=0.9545, ValLoss=0.2665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Val Loss: 0.2665, Val Acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  84%|████████▍ | 21/25 [02:31<00:29,  7.36s/it, TrainAcc=1.0000, TrainLoss=0.0092]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 => Train Loss: 0.0092, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  88%|████████▊ | 22/25 [02:38<00:21,  7.29s/it, TrainAcc=1.0000, TrainLoss=0.0083]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 => Train Loss: 0.0083, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  92%|█████████▏| 23/25 [02:45<00:14,  7.16s/it, TrainAcc=1.0000, TrainLoss=0.0076]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 => Train Loss: 0.0076, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  96%|█████████▌| 24/25 [02:52<00:07,  7.09s/it, TrainAcc=1.0000, TrainLoss=0.0069]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 => Train Loss: 0.0069, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  96%|█████████▌| 24/25 [02:59<00:07,  7.09s/it, TrainAcc=1.0000, TrainLoss=0.0064]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 => Train Loss: 0.0064, Train Acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 25/25 [03:01<00:00,  7.25s/it, TrainAcc=1.0000, TrainLoss=0.0064, ValAcc=0.9545, ValLoss=0.2774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Val Loss: 0.2774, Val Acc: 0.9545\n",
      "\n",
      "--- Training Finished ---\n",
      "\n",
      "--- Evaluating on Test Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 0.2774\n",
      "Final Test Accuracy: 0.9545\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          G1       1.00      1.00      1.00         8\n",
      "          G2       0.86      1.00      0.92         6\n",
      "          G3       1.00      0.86      0.92         7\n",
      "          G4       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.96      0.96      0.96        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm # Added tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_ROOT = Path(\"../data/GAMEEMO\") # Assuming data is in a subfolder \"GAMEEMO\"\n",
    "NUM_EPOCHS = 25 # Adjust as needed\n",
    "BATCH_SIZE = 16 # Adjust based on your GPU memory\n",
    "LEARNING_RATE = 0.001\n",
    "TEST_SPLIT_RATIO = 0.2\n",
    "NUM_CLASSES = 4 # G1, G2, G3, G4\n",
    "NUM_CHANNELS = 14 # As per dataset description\n",
    "FIXED_SEQUENCE_LENGTH = 3000 # Example, adjust after inspecting data\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "\n",
    "def g_label(fn_name):\n",
    "    \"\"\"Extracts game label (0-3) from a filename.\"\"\"\n",
    "    match = re.search(r\"G([1-4])\", fn_name)\n",
    "    if match:\n",
    "        return int(match.group(1)) - 1\n",
    "    raise ValueError(f\"Could not extract label from {fn_name}\")\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for GAMEEMO EEG data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_root, fixed_sequence_length, transform=None):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.fixed_sequence_length = fixed_sequence_length\n",
    "        self.transform = transform\n",
    "        self.eeg_paths = []\n",
    "        self.labels = []\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Loads all EEG file paths and their corresponding labels.\"\"\"\n",
    "        print(f\"Scanning data root: {self.data_root.resolve()}\")\n",
    "        if not self.data_root.exists():\n",
    "            print(f\"ERROR: Data root directory '{self.data_root.resolve()}' does not exist.\")\n",
    "            print(\"Please ensure the GAMEEMO dataset is downloaded and extracted to this location,\")\n",
    "            print(\"or update the DATA_ROOT variable in the script.\")\n",
    "            return\n",
    "\n",
    "        subject_count = 0\n",
    "        for subj_dir in self.data_root.iterdir():\n",
    "            if subj_dir.is_dir() and re.fullmatch(r\"\\(S\\d{2}\\)\", subj_dir.name):\n",
    "                subject_count +=1\n",
    "                csv_dir = subj_dir / \"Preprocessed EEG Data\" / \".csv format\"\n",
    "                if csv_dir.exists():\n",
    "                    for p in csv_dir.glob(\"*.csv\"):\n",
    "                        try:\n",
    "                            label = g_label(p.name)\n",
    "                            self.eeg_paths.append(p)\n",
    "                            self.labels.append(label)\n",
    "                        except ValueError:\n",
    "                            # Silently skip files with label errors, or log to a file\n",
    "                            pass\n",
    "                # else:\n",
    "                    # Optionally log if a subject folder is missing the CSV directory\n",
    "                    # print(f\"Warning: .csv format directory not found in {subj_dir}\")\n",
    "        \n",
    "        if subject_count == 0:\n",
    "            print(f\"Warning: No subject directories like (SXX) found in {self.data_root.resolve()}\")\n",
    "        print(f\"Found {len(self.eeg_paths)} recordings from {subject_count} subjects.\")\n",
    "        if not self.eeg_paths:\n",
    "            print(\"CRITICAL: No EEG files were found. Please check the DATA_ROOT path and dataset structure.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.eeg_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, header=0) # Explicitly state header is on row 0\n",
    "\n",
    "            # Corrected logic: User specified the comma is at the END of the header.\n",
    "            # This means pandas might create an extra unnamed column at the end.\n",
    "            # We should take the FIRST NUM_CHANNELS columns.\n",
    "            if df.shape[1] == NUM_CHANNELS + 1:\n",
    "                # If there's an extra column, assume it's the last one due to trailing comma\n",
    "                df = df.iloc[:, :NUM_CHANNELS]\n",
    "            elif df.shape[1] == NUM_CHANNELS:\n",
    "                # Correct number of columns\n",
    "                pass\n",
    "            else:\n",
    "                # Incorrect number of columns for data\n",
    "                # Log this error if necessary, but avoid spammy prints\n",
    "                # print(f\"Error: File {file_path.name} has {df.shape[1]} data columns after header, expected {NUM_CHANNELS}. Skipping.\")\n",
    "                return None, None\n",
    "\n",
    "            eeg_data = df.values.astype(np.float32)\n",
    "\n",
    "            # Pad or truncate sequence\n",
    "            if eeg_data.shape[0] > self.fixed_sequence_length:\n",
    "                eeg_data = eeg_data[:self.fixed_sequence_length, :]\n",
    "            else:\n",
    "                padding_rows = self.fixed_sequence_length - eeg_data.shape[0]\n",
    "                if padding_rows > 0: # Ensure padding is only added if needed\n",
    "                    padding = np.zeros((padding_rows, NUM_CHANNELS), dtype=np.float32)\n",
    "                    eeg_data = np.vstack((eeg_data, padding))\n",
    "            \n",
    "            # Ensure eeg_data has the correct shape before transposing\n",
    "            if eeg_data.shape[1] != NUM_CHANNELS:\n",
    "                # This case should ideally be caught earlier\n",
    "                # print(f\"Error: File {file_path.name} data has {eeg_data.shape[1]} channels after processing, expected {NUM_CHANNELS}. Skipping.\")\n",
    "                return None, None\n",
    "\n",
    "            # Transpose to (channels, sequence_length) for Conv1D\n",
    "            eeg_data = eeg_data.T # (NUM_CHANNELS, fixed_sequence_length)\n",
    "\n",
    "            if self.transform:\n",
    "                eeg_data = self.transform(eeg_data)\n",
    "\n",
    "            return torch.tensor(eeg_data, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        except pd.errors.EmptyDataError:\n",
    "            # print(f\"Warning: File {file_path.name} is empty. Skipping.\")\n",
    "            return None, None\n",
    "        except Exception: # Catch other potential errors during file processing\n",
    "            # print(f\"Error processing file {file_path.name}: {e}. Skipping.\")\n",
    "            return None, None\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function to filter out None items from the batch.\n",
    "    These None items can result from file processing errors in __getitem__.\n",
    "    \"\"\"\n",
    "    # Filter out None items\n",
    "    batch = [item for item in batch if item[0] is not None and item[1] is not None]\n",
    "    if not batch: # If all items in the batch failed\n",
    "        return None, None \n",
    "    # Use default_collate for the valid items\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "\n",
    "# --- 2. Model Architecture (CNN + LSTM) ---\n",
    "class EEG_CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels, sequence_length, lstm_hidden_size=128, num_lstm_layers=1):\n",
    "        super(EEG_CNN_LSTM, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        # CNN part for spatial feature extraction\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        # Output of pool1: (batch, 32, sequence_length / 2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        # Output of pool2: (batch, 64, sequence_length / 4)\n",
    "        \n",
    "        self.lstm_input_features = 64\n",
    "        # LSTM part for temporal feature extraction\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_features,\n",
    "                              hidden_size=lstm_hidden_size,\n",
    "                              num_layers=num_lstm_layers,\n",
    "                              batch_first=True) # batch_first=True means input/output shape is (batch, seq, feature)\n",
    "\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_channels, sequence_length)\n",
    "        \n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        # x shape after CNN: (batch_size, 64, sequence_length / 4)\n",
    "\n",
    "        x = x.permute(0, 2, 1) # (batch_size, sequence_length / 4, 64)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # h_n shape: (num_lstm_layers, batch_size, lstm_hidden_size)\n",
    "        # We want the last layer's hidden state: h_n[-1] -> (batch_size, lstm_hidden_size)\n",
    "        x = h_n[-1] \n",
    "\n",
    "        x = self.fc(x)\n",
    "        # x shape: (batch_size, num_classes)\n",
    "        return x\n",
    "\n",
    "# --- 3. Training and Evaluation Functions ---\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epoch_num, total_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Wrap train_loader with tqdm for a progress bar\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch_num+1}/{total_epochs} [Train]\", leave=False)\n",
    "    for inputs, labels in progress_bar:\n",
    "        if inputs is None or labels is None : # Handle cases where collate_fn returned None\n",
    "            continue # Skip this batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update tqdm progress bar\n",
    "        progress_bar.set_postfix(loss=running_loss/total_samples if total_samples > 0 else 0, \n",
    "                                 acc=correct_predictions/total_samples if total_samples > 0 else 0)\n",
    "\n",
    "    if total_samples == 0: # All batches might have been skipped\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, epoch_num, total_epochs, eval_type=\"Val\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Wrap test_loader with tqdm for a progress bar\n",
    "    progress_bar = tqdm(test_loader, desc=f\"Epoch {epoch_num+1}/{total_epochs} [{eval_type}]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in progress_bar:\n",
    "            if inputs is None or labels is None :\n",
    "                continue # Skip this batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            progress_bar.set_postfix(loss=running_loss/total_samples if total_samples > 0 else 0,\n",
    "                                     acc=correct_predictions/total_samples if total_samples > 0 else 0)\n",
    "\n",
    "    if total_samples == 0: # All batches might have been skipped\n",
    "        return 0.0, 0.0, [], []\n",
    "        \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc, all_labels, all_predictions\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix'):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout() # Adjust layout to prevent labels from being cut off\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create dataset\n",
    "    print(\"Initializing dataset...\")\n",
    "    full_dataset = EEGDataset(data_root=DATA_ROOT, fixed_sequence_length=FIXED_SEQUENCE_LENGTH)\n",
    "\n",
    "    if not full_dataset.eeg_paths:\n",
    "        print(\"No data loaded. Exiting.\")\n",
    "        exit()\n",
    "        \n",
    "    # Split dataset\n",
    "    num_samples = len(full_dataset)\n",
    "    test_size = int(TEST_SPLIT_RATIO * num_samples)\n",
    "    train_size = num_samples - test_size\n",
    "    \n",
    "    if train_size <= 0 or test_size <= 0:\n",
    "        min_samples_needed = int(1 / TEST_SPLIT_RATIO) if TEST_SPLIT_RATIO > 0 else 2 # Basic check\n",
    "        print(f\"Dataset too small for splitting with ratio {TEST_SPLIT_RATIO}. Need at least {min_samples_needed} samples for a split.\")\n",
    "        if num_samples > 0:\n",
    "             train_dataset = full_dataset\n",
    "             # For evaluation, it's better to have a separate test set.\n",
    "             # If forced to use the same, be aware of inflated metrics.\n",
    "             # Consider a warning or different handling if this is not acceptable.\n",
    "             print(f\"Warning: Using all {num_samples} samples for training. No separate test set for validation during epoch. Final evaluation will be on this data.\")\n",
    "             # Create a DataLoader for the full dataset to be used as 'test_loader' for validation reports\n",
    "             test_dataset = full_dataset # This means val_loss/acc will be on training data if no proper split\n",
    "        else:\n",
    "            print(\"CRITICAL: Dataset is empty after initialization. Cannot proceed.\")\n",
    "            exit()\n",
    "    else:\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "    print(f\"Number of testing samples: {len(test_dataset)}\")\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn, num_workers=0, pin_memory=True if device.type=='cuda' else False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn, num_workers=0, pin_memory=True if device.type=='cuda' else False)\n",
    "\n",
    "    # Initialize model, criterion, optimizer\n",
    "    model = EEG_CNN_LSTM(num_classes=NUM_CLASSES, num_channels=NUM_CHANNELS, sequence_length=FIXED_SEQUENCE_LENGTH).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "    # Overall progress bar for epochs\n",
    "    epoch_progress_bar = tqdm(range(NUM_EPOCHS), desc=\"Epochs\")\n",
    "    for epoch in epoch_progress_bar:\n",
    "        train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device, epoch, NUM_EPOCHS)\n",
    "        \n",
    "        # Update epoch progress bar postfix with training results\n",
    "        epoch_progress_bar.set_postfix(TrainLoss=f\"{train_loss:.4f}\", TrainAcc=f\"{train_acc:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} => Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\", end=\"\")\n",
    "\n",
    "        # Evaluate on the test set (as validation) periodically\n",
    "        if (epoch + 1) % 5 == 0 or epoch == NUM_EPOCHS - 1:\n",
    "            val_loss, val_acc, _, _ = evaluate_model(model, test_loader, criterion, device, epoch, NUM_EPOCHS, eval_type=\"Val\")\n",
    "            print(f\" -- Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            # Also update epoch_progress_bar if you want validation results there too\n",
    "            epoch_progress_bar.set_postfix(TrainLoss=f\"{train_loss:.4f}\", TrainAcc=f\"{train_acc:.4f}\", ValLoss=f\"{val_loss:.4f}\", ValAcc=f\"{val_acc:.4f}\")\n",
    "        else:\n",
    "            print() # Newline if no validation print\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    print(\"\\n--- Evaluating on Test Set ---\")\n",
    "    # Re-use evaluate_model, final evaluation on the test_loader\n",
    "    test_loss, test_acc, true_labels, predicted_labels = evaluate_model(model, test_loader, criterion, device, NUM_EPOCHS-1, NUM_EPOCHS, eval_type=\"Test\") # epoch_num is just for desc\n",
    "    print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    if true_labels and predicted_labels: # Check if lists are not empty\n",
    "        # Classification Report\n",
    "        class_names = [f\"G{i+1}\" for i in range(NUM_CLASSES)] # G1, G2, G3, G4\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(true_labels, predicted_labels, target_names=class_names, zero_division=0))\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(true_labels, predicted_labels)\n",
    "        plot_confusion_matrix(cm, class_names=class_names, title=\"Test Set Confusion Matrix\")\n",
    "    else:\n",
    "        print(\"Could not generate classification report or confusion matrix due to lack of evaluation results (possibly all batches failed or test set was empty).\")\n",
    "\n",
    "    # Example of saving the model\n",
    "    # torch.save(model.state_dict(), 'eeg_emotion_model_v2.pth')\n",
    "    # print(\"Model saved to eeg_emotion_model_v2.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
