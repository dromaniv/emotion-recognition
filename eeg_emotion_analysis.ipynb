{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4662cc93",
   "metadata": {},
   "source": [
    "# EEG Emotion Recognition Notebook\n",
    "\n",
    "This notebook implements a CNN+LSTM model for emotion recognition using EEG data from the GAMEEMO dataset. The code is organized into sections with explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6347950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bffa0b",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up paths and hyperparameters."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DATA_ROOT = Path(\"../data/GAMEEMO\")  # User updated path\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001\n",
    "TEST_SPLIT_RATIO = 0.2\n",
    "NUM_CLASSES = 4\n",
    "NUM_CHANNELS = 14\n",
    "FIXED_SEQUENCE_LENGTH = 3000\n",
    "MODEL_SAVE_PATH = \"models/eeg_emotion_best_accuracy_model.pth\"\n",
    "\n",
    "# Early Stopping Configuration\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "EARLY_STOPPING_MIN_DELTA = 0.001  # For validation loss\n",
    "\n",
    "Path(\"../models\").mkdir(parents=True, exist_ok=True)"
   ],
   "id": "3eb03555a720bfcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the dataset if it does not exist\n",
    "if not any(DATA_ROOT.rglob(\"*.csv\")):\n",
    "    print(\"Downloading GAMEEMO\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"kaggle\",\n",
    "                \"datasets\",\n",
    "                \"download\",\n",
    "                \"-d\",\n",
    "                \"sigfest/database-for-emotion-recognition-system-gameemo\",\n",
    "                \"-p\",\n",
    "                str(DATA_ROOT.parent),\n",
    "                \"--unzip\",\n",
    "            ],\n",
    "            check=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f\"⚠️ Kaggle download failed: {e}\\n\")\n",
    "else:\n",
    "    print(\"Dataset already present - skipping download.\")"
   ],
   "id": "296fcfca4820a742"
  },
  {
   "cell_type": "markdown",
   "id": "52d83368",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "Define helper functions and a custom Dataset class to load and preprocess EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d196e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_label(fn_name):\n",
    "    \"\"\"Extracts game label (0-3) from a filename.\"\"\"\n",
    "    match = re.search(r\"G([1-4])\", fn_name)\n",
    "    if match:\n",
    "        return int(match.group(1)) - 1\n",
    "    raise ValueError(f\"Could not extract label from {fn_name}\")\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for GAMEEMO EEG data.\"\"\"\n",
    "    def __init__(self, data_root, fixed_sequence_length, transform=None):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.fixed_sequence_length = fixed_sequence_length\n",
    "        self.transform = transform\n",
    "        self.eeg_paths = []\n",
    "        self.labels = []\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Loads all EEG file paths and their corresponding labels.\"\"\"\n",
    "        if not self.data_root.exists():\n",
    "            print(f\"ERROR: Data root directory '{self.data_root.resolve()}' does not exist.\")\n",
    "            return\n",
    "\n",
    "        subject_count = 0\n",
    "        for subj_dir in self.data_root.iterdir():\n",
    "            if subj_dir.is_dir() and re.fullmatch(r\"\\(S\\d{2}\\)\", subj_dir.name):\n",
    "                subject_count +=1\n",
    "                csv_dir = subj_dir / \"Preprocessed EEG Data\" / \".csv format\"\n",
    "                if csv_dir.exists():\n",
    "                    for p in csv_dir.glob(\"*.csv\"):\n",
    "                        try:\n",
    "                            label = g_label(p.name)\n",
    "                            self.eeg_paths.append(p)\n",
    "                            self.labels.append(label)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "\n",
    "        print(f\"Found {len(self.eeg_paths)} recordings from {subject_count} subjects.\")\n",
    "        if not self.eeg_paths:\n",
    "            print(\"CRITICAL: No EEG files were found. Please check DATA_ROOT and dataset structure.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.eeg_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, header=0)\n",
    "            if df.shape[1] == NUM_CHANNELS + 1:\n",
    "                df = df.iloc[:, :NUM_CHANNELS]\n",
    "            elif df.shape[1] == NUM_CHANNELS:\n",
    "                pass\n",
    "            else:\n",
    "                return None, None\n",
    "\n",
    "            eeg_data = df.values.astype(np.float32)\n",
    "            if eeg_data.shape[0] > self.fixed_sequence_length:\n",
    "                eeg_data = eeg_data[:self.fixed_sequence_length, :]\n",
    "            else:\n",
    "                padding_rows = self.fixed_sequence_length - eeg_data.shape[0]\n",
    "                if padding_rows > 0:\n",
    "                    padding = np.zeros((padding_rows, NUM_CHANNELS), dtype=np.float32)\n",
    "                    eeg_data = np.vstack((eeg_data, padding))\n",
    "\n",
    "            if eeg_data.shape[1] != NUM_CHANNELS:\n",
    "                return None, None\n",
    "\n",
    "            eeg_data = eeg_data.T\n",
    "            if self.transform:\n",
    "                eeg_data = self.transform(eeg_data)\n",
    "\n",
    "            return torch.tensor(eeg_data, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        except pd.errors.EmptyDataError:\n",
    "            return None, None\n",
    "        except Exception:\n",
    "            return None, None\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"Collate function to filter out None items from the batch.\"\"\"\n",
    "    batch = [item for item in batch if item[0] is not None and item[1] is not None]\n",
    "    if not batch:\n",
    "        return None, None\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12c8d4",
   "metadata": {},
   "source": [
    "## 2. Model Architecture (CNN + LSTM)\n",
    "\n",
    "Define the CNN+LSTM model for EEG classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd81d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_CNN_LSTM(nn.Module):\n",
    "    \"\"\"CNN followed by LSTM for EEG classification.\"\"\"\n",
    "    def __init__(self, num_classes, num_channels, sequence_length, lstm_hidden_size=128, num_lstm_layers=1, dropout_rate=0.5):\n",
    "        super(EEG_CNN_LSTM, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.dropout_cnn = nn.Dropout(dropout_rate / 2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.lstm_input_features = 64\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_features,\n",
    "                          hidden_size=lstm_hidden_size,\n",
    "                          num_layers=num_lstm_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout_rate if num_lstm_layers > 1 else 0)\n",
    "\n",
    "        self.dropout_fc = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.dropout_cnn(x)\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        x = h_n[-1]\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ab24b",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluation Functions\n",
    "\n",
    "Define functions to train and evaluate the model, and to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc35716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False, unit=\"batch\")\n",
    "    for inputs, labels in progress_bar:\n",
    "        if inputs is None or labels is None:\n",
    "            continue\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        if total_samples > 0:\n",
    "            progress_bar.set_postfix(loss=running_loss/total_samples, acc=correct_predictions/total_samples)\n",
    "\n",
    "    if total_samples == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device, eval_type=\"Validation\"):\n",
    "    \"\"\"Evaluates the model on the validation/test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    progress_bar = tqdm(val_loader, desc=eval_type, leave=False, unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in progress_bar:\n",
    "            if inputs is None or labels is None:\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            if total_samples > 0:\n",
    "                progress_bar.set_postfix(loss=running_loss/total_samples, acc=correct_predictions/total_samples)\n",
    "\n",
    "    if total_samples == 0:\n",
    "        return 0.0, 0.0, [], []\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc, all_labels, all_predictions\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix'):\n",
    "    \"\"\"Plots a confusion matrix using seaborn and matplotlib.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b980f",
   "metadata": {},
   "source": [
    "## 4. Main Execution\n",
    "\n",
    "Run data loading, model initialization, training, and final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99664c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing dataset...\n",
      "Found 112 recordings from 28 subjects.\n",
      "Number of training samples: 90\n",
      "Number of testing samples: 22\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 => Train Loss: 1.3951, Train Acc: 0.2111 | Val Loss: 1.3702, Val Acc: 0.3182 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.3182. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 => Train Loss: 1.3608, Train Acc: 0.4333 | Val Loss: 1.3583, Val Acc: 0.2273 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 => Train Loss: 1.3321, Train Acc: 0.4333 | Val Loss: 1.3431, Val Acc: 0.3182 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 => Train Loss: 1.3110, Train Acc: 0.4111 | Val Loss: 1.3204, Val Acc: 0.3636 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.3636. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 => Train Loss: 1.2793, Train Acc: 0.4444 | Val Loss: 1.2948, Val Acc: 0.4091 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.4091. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 => Train Loss: 1.2028, Train Acc: 0.5222 | Val Loss: 1.2515, Val Acc: 0.3636 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 => Train Loss: 1.1490, Train Acc: 0.6000 | Val Loss: 1.2367, Val Acc: 0.4545 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.4545. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 => Train Loss: 1.0722, Train Acc: 0.6222 | Val Loss: 1.2156, Val Acc: 0.4545 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 => Train Loss: 0.9571, Train Acc: 0.6667 | Val Loss: 1.1522, Val Acc: 0.5909 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.5909. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 => Train Loss: 0.9384, Train Acc: 0.6222 | Val Loss: 1.0481, Val Acc: 0.6818 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.6818. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 => Train Loss: 0.8619, Train Acc: 0.7000 | Val Loss: 1.0429, Val Acc: 0.6818 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 => Train Loss: 0.7961, Train Acc: 0.7556 | Val Loss: 1.0193, Val Acc: 0.6364 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 => Train Loss: 0.6436, Train Acc: 0.8667 | Val Loss: 0.9710, Val Acc: 0.6818 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 => Train Loss: 0.6003, Train Acc: 0.8333 | Val Loss: 0.9033, Val Acc: 0.7727 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.7727. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 => Train Loss: 0.4944, Train Acc: 0.8444 | Val Loss: 0.8544, Val Acc: 0.7727 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 => Train Loss: 0.5087, Train Acc: 0.8222 | Val Loss: 0.8156, Val Acc: 0.6818 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 => Train Loss: 0.4318, Train Acc: 0.8778 | Val Loss: 0.8552, Val Acc: 0.7273 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 => Train Loss: 0.3912, Train Acc: 0.8667 | Val Loss: 0.7775, Val Acc: 0.7727 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 => Train Loss: 0.3346, Train Acc: 0.8667 | Val Loss: 0.6386, Val Acc: 0.7727 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 => Train Loss: 0.4354, Train Acc: 0.8667 | Val Loss: 0.5521, Val Acc: 0.8636 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.8636. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 => Train Loss: 0.4380, Train Acc: 0.8556 | Val Loss: 0.6126, Val Acc: 0.7727 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 => Train Loss: 0.3919, Train Acc: 0.8556 | Val Loss: 0.6435, Val Acc: 0.8636 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 => Train Loss: 0.3203, Train Acc: 0.9111 | Val Loss: 0.5502, Val Acc: 0.9091 | LR: 1.0e-03\n",
      "*** New best validation accuracy: 0.9091. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 => Train Loss: 0.2583, Train Acc: 0.9111 | Val Loss: 0.5034, Val Acc: 0.8636 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 => Train Loss: 0.2180, Train Acc: 0.9556 | Val Loss: 0.4988, Val Acc: 0.8636 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 => Train Loss: 0.1641, Train Acc: 0.9778 | Val Loss: 0.5021, Val Acc: 0.8636 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 => Train Loss: 0.1278, Train Acc: 0.9667 | Val Loss: 0.4852, Val Acc: 0.8182 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 => Train Loss: 0.1472, Train Acc: 0.9667 | Val Loss: 0.5500, Val Acc: 0.8182 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 => Train Loss: 0.1247, Train Acc: 0.9778 | Val Loss: 0.7625, Val Acc: 0.7727 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 => Train Loss: 0.1243, Train Acc: 0.9778 | Val Loss: 0.5936, Val Acc: 0.8182 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 => Train Loss: 0.0909, Train Acc: 0.9889 | Val Loss: 0.5263, Val Acc: 0.7727 | LR: 1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 => Train Loss: 0.0733, Train Acc: 1.0000 | Val Loss: 0.5104, Val Acc: 0.7727 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 => Train Loss: 0.1630, Train Acc: 0.9556 | Val Loss: 0.4739, Val Acc: 0.8182 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 => Train Loss: 0.0618, Train Acc: 1.0000 | Val Loss: 0.4073, Val Acc: 0.8636 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 => Train Loss: 0.0610, Train Acc: 1.0000 | Val Loss: 0.3380, Val Acc: 0.8636 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 => Train Loss: 0.0478, Train Acc: 1.0000 | Val Loss: 0.2824, Val Acc: 0.8636 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 => Train Loss: 0.0492, Train Acc: 1.0000 | Val Loss: 0.2737, Val Acc: 0.8636 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 => Train Loss: 0.0583, Train Acc: 0.9889 | Val Loss: 0.2845, Val Acc: 0.9091 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 => Train Loss: 0.0378, Train Acc: 1.0000 | Val Loss: 0.2873, Val Acc: 0.9545 | LR: 2.0e-04\n",
      "*** New best validation accuracy: 0.9545. Saving model state. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 => Train Loss: 0.0659, Train Acc: 0.9889 | Val Loss: 0.2919, Val Acc: 0.9545 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 => Train Loss: 0.0460, Train Acc: 0.9889 | Val Loss: 0.2925, Val Acc: 0.9545 | LR: 2.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 => Train Loss: 0.0459, Train Acc: 1.0000 | Val Loss: 0.2917, Val Acc: 0.9545 | LR: 4.0e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 => Train Loss: 0.0352, Train Acc: 1.0000 | Val Loss: 0.2828, Val Acc: 0.9545 | LR: 4.0e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 => Train Loss: 0.0339, Train Acc: 1.0000 | Val Loss: 0.2878, Val Acc: 0.9091 | LR: 4.0e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 => Train Loss: 0.0275, Train Acc: 1.0000 | Val Loss: 0.2878, Val Acc: 0.9091 | LR: 4.0e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 => Train Loss: 0.0288, Train Acc: 1.0000 | Val Loss: 0.2913, Val Acc: 0.9091 | LR: 8.0e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 => Train Loss: 0.0547, Train Acc: 0.9889 | Val Loss: 0.2831, Val Acc: 0.9545 | LR: 8.0e-06\n",
      "\n",
      "Early stopping triggered after 47 epochs: validation loss did not improve for 10 consecutive epochs.\n",
      "Best validation loss achieved: 0.2737\n",
      "\n",
      "--- Training Finished ---\n",
      "Loading model with best validation accuracy: 0.9545 for final evaluation.\n",
      "Model with best validation accuracy saved to ../models/eeg_emotion_best_accuracy_model.pth\n",
      "\n",
      "--- Evaluating on Test Set (with best accuracy model) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 0.2873\n",
      "Final Test Accuracy: 0.9545 (from model that had best val_acc: 0.9545)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          G1       0.83      1.00      0.91         5\n",
      "          G2       1.00      0.80      0.89         5\n",
      "          G3       1.00      1.00      1.00         7\n",
      "          G4       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.96      0.95      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Initializing dataset...\")\n",
    "full_dataset = EEGDataset(data_root=DATA_ROOT, fixed_sequence_length=FIXED_SEQUENCE_LENGTH)\n",
    "\n",
    "if not full_dataset.eeg_paths:\n",
    "    print(\"No data loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "num_samples = len(full_dataset)\n",
    "test_size = int(TEST_SPLIT_RATIO * num_samples)\n",
    "train_size = num_samples - test_size\n",
    "\n",
    "if train_size <= 0 or test_size <= 0:\n",
    "    min_samples_needed = int(1 / TEST_SPLIT_RATIO) if TEST_SPLIT_RATIO > 0 else 2\n",
    "    print(f\"Dataset too small for splitting with ratio {TEST_SPLIT_RATIO}. Need at least {min_samples_needed} samples.\")\n",
    "    if num_samples > 0:\n",
    "            train_dataset = full_dataset\n",
    "            test_dataset = full_dataset\n",
    "            print(f\"Warning: Using all {num_samples} samples for training and testing due to small dataset size.\")\n",
    "    else:\n",
    "        print(\"CRITICAL: Dataset is empty after initialization. Cannot proceed.\")\n",
    "        exit()\n",
    "else:\n",
    "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_dataset)}\")\n",
    "\n",
    "num_workers = 0\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn, num_workers=num_workers, pin_memory=True if device.type=='cuda' else False)\n",
    "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn, num_workers=num_workers, pin_memory=True if device.type=='cuda' else False)\n",
    "\n",
    "model = EEG_CNN_LSTM(num_classes=NUM_CLASSES, num_channels=NUM_CHANNELS, sequence_length=FIXED_SEQUENCE_LENGTH, dropout_rate=0.5).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "epochs_no_improve_loss = 0\n",
    "best_model_state_accuracy = None\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, device, eval_type=\"Validation\")\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} => \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | \"\n",
    "            f\"LR: {current_lr:.1e}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state_accuracy = copy.deepcopy(model.state_dict())\n",
    "        print(f\"*** New best validation accuracy: {best_val_acc:.4f}. Saving model state. ***\")\n",
    "\n",
    "    if val_loss < best_val_loss - EARLY_STOPPING_MIN_DELTA:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve_loss = 0\n",
    "    else:\n",
    "        epochs_no_improve_loss += 1\n",
    "\n",
    "    if epochs_no_improve_loss >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs: validation loss did not improve for {EARLY_STOPPING_PATIENCE} consecutive epochs.\")\n",
    "        print(f\"Best validation loss achieved: {best_val_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "if best_model_state_accuracy:\n",
    "    print(f\"Loading model with best validation accuracy: {best_val_acc:.4f} for final evaluation.\")\n",
    "    model.load_state_dict(best_model_state_accuracy)\n",
    "    try:\n",
    "        torch.save(best_model_state_accuracy, MODEL_SAVE_PATH)\n",
    "        print(f\"Model with best validation accuracy saved to {MODEL_SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "else:\n",
    "    print(\"No best model state recorded.\")\n",
    "\n",
    "print(\"\\n--- Evaluating on Test Set (with best accuracy model) ---\")\n",
    "test_loss, test_acc, true_labels, predicted_labels = evaluate_model(model, val_loader, criterion, device, eval_type=\"Test\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f} (from model that had best val_acc: {best_val_acc:.4f})\")\n",
    "\n",
    "if true_labels and predicted_labels:\n",
    "    class_names = [f\"G{i+1}\" for i in range(NUM_CLASSES)]\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predicted_labels, target_names=class_names, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    plot_confusion_matrix(cm, class_names=class_names, title=\"Test Set Confusion Matrix (Best Accuracy Model)\")\n",
    "else:\n",
    "    print(\"Could not generate classification report or confusion matrix (no evaluation results).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5393776",
   "metadata": {},
   "source": [
    "## Model Architecture and Citations\n",
    "\n",
    "The model implemented is a hybrid deep learning architecture combining:\n",
    "\n",
    "1. **Convolutional Neural Networks (CNNs)**: Specifically, 1D CNNs are used for initial feature extraction from the EEG channels.\n",
    "2. **Long Short-Term Memory (LSTM) Networks**: Following the CNN layers, an LSTM network models temporal dependencies in the sequence of features.\n",
    "\n",
    "Citations:\n",
    "- LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). *Gradient-based learning applied to document recognition.* Proceedings of the IEEE, 86(11), 2278-2324.\n",
    "- Hochreiter, S., & Schmidhuber, J. (1997). *Long short-term memory.* Neural computation, 9(8), 1735-1780."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
